{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba12a8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce17db6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b724db47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([68, 3000, 9]) tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.3037, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.5023, 0.0000, 0.3563, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.4507, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0563, 0.0000, 0.0000, 0.3300,\n",
      "        0.0000, 0.0000, 0.3640, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.2053, 0.0000, 0.0000, 0.4507])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import YXJ\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TimeSeriesDataset2(Dataset):\n",
    "    def __init__(self, csv_file, window_size, step_size):\n",
    "        self.data_frame = pd.read_csv(csv_file) # 读取CSV文件\n",
    "        self.window_size = window_size\n",
    "        self.step_size = step_size\n",
    "        self.samples = self._create_samples()\n",
    "\n",
    "    def _create_samples(self):\n",
    "        samples = []\n",
    "        for start_pos in range(0, len(self.data_frame) - self.window_size + 1, self.step_size):\n",
    "            end_pos = start_pos + self.window_size\n",
    "            sample = self.data_frame.iloc[start_pos:end_pos].values\n",
    "            samples.append(sample)\n",
    "        return np.array(samples)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "        X = sample[:, :-1]  # 所有行，除了最后一列\n",
    "        y = np.mean(sample[:, -1])  # 最后一列的平均值作为标签\n",
    "\n",
    "        # 转换为Tensor\n",
    "        X = torch.tensor(X, dtype=torch.float32)\n",
    "       # X = X.transpose(0, 1)\n",
    "        y = torch.tensor(y, dtype=torch.float32)\n",
    "        return X, y\n",
    "\n",
    "# 使用示例\n",
    "SAMPLES_PER_GESTURE = 3000\n",
    "step_size = 100\n",
    "dataset = TimeSeriesDataset2('normalized_data.csv', SAMPLES_PER_GESTURE,step_size)\n",
    "GESTURES = [\"smoke\", \"nosmoke\"]  # 手势列表\n",
    "NUM_GESTURES= len(GESTURES);\n",
    "\n",
    "# 分割数据集\n",
    "from torch.utils.data import random_split\n",
    "dataset_size = len(dataset)\n",
    "train_size = int(dataset_size * 0.7)  # 70% 数据用于训练\n",
    "valid_size = int(dataset_size * 0.2)  # 20% 数据用于验证\n",
    "test_size = dataset_size - train_size - valid_size  # 剩余10% 用于测试\n",
    "batch_size =512;\n",
    "train_dataset, valid_dataset, test_dataset = random_split(dataset, [train_size, valid_size, test_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size, shuffle=False)\n",
    "\n",
    "YXJ.check_dataloader(test_loader)\n",
    "input_size=SAMPLES_PER_GESTURE*9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "991ecf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return x\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_dim, num_heads, num_encoder_layers, dim_feedforward, max_seq_length, num_classes=1):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.embedding = nn.Linear(input_dim, dim_feedforward)\n",
    "        self.pos_encoder = PositionalEncoding(dim_feedforward, max_seq_length)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=dim_feedforward, nhead=num_heads, dim_feedforward=dim_feedforward)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_encoder_layers)\n",
    "        self.output_layer = nn.Linear(dim_feedforward, num_classes)\n",
    "\n",
    "    def forward(self, src):\n",
    "        src = src.transpose(0, 1)\n",
    "        src = self.embedding(src) * math.sqrt(dim_feedforward)\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src)\n",
    "        output = self.output_layer(output.mean(dim=0))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0204bbb-77d3-401f-bdf6-5b9d948fcbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, device, criterion, test_loader):\n",
    "    model.eval()\n",
    "    validation_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            validation_loss += criterion(output, target).item()\n",
    "    validation_loss /= len(test_loader)  # 计算平均验证损失\n",
    "    return validation_loss\n",
    "    \n",
    "def train(model, device, train_loader, criterion, optimizer, epochs):\n",
    "    model.train()\n",
    "    train_losses = []  # 用于存储每个epoch的损失值\n",
    "    for epoch in range(epochs):\n",
    "        for data, target in train_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()           # 清零梯度\n",
    "            output = model(data)            # 前向传播\n",
    "            loss = criterion(output, target) # 计算损失\n",
    "            loss.backward()                 # 反向传播\n",
    "            optimizer.step()                # 更新参数\n",
    "        train_losses.append(loss.item())\n",
    "        print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
    "    return train_losses\n",
    "    \n",
    "def train_vali(model, device, train_loader, test_loader, criterion, optimizer, epochs):\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    validation_losses = []\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for data, target in train_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()  # 清零梯度\n",
    "            output = model(data)  # 前向传播\n",
    "            loss = criterion(output, target)  # 计算损失\n",
    "            loss.backward()  # 反向传播\n",
    "            optimizer.step()  # 更新参数\n",
    "        train_losses.append(loss.item())\n",
    "        \n",
    "        # 在每个epoch后计算验证集上的损失\n",
    "        validation_loss = validate(model, device, criterion, test_loader)\n",
    "        validation_losses.append(validation_loss)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}, Training Loss: {loss.item()}, Validation Loss: {validation_loss}')\n",
    "\n",
    "    return train_losses, validation_losses\n",
    "    \n",
    "def test(model, device, test_loader):\n",
    "    model.eval()  # 将模型设置为评估模式\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():  # 在评估阶段不计算梯度\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            # 计算MSE损失，注意这里不需要像之前那样手动计算差异\n",
    "            # 使用output和target直接计算MSE\n",
    "            loss = torch.nn.functional.mse_loss(output.squeeze(), target)\n",
    "            # 累加每个批次的损失\n",
    "            test_loss += loss.item() * data.size(0)  # 乘以data.size(0)以得到此批次的总损失\n",
    "\n",
    "    # 计算整个测试集上的平均损失\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    \n",
    "    print(f'Average MSE Loss on the test set: {test_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df0eda1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qiushi11/anaconda3/lib/python3.11/site-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "# 使用GPU\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device=torch.device('cuda' if use_cuda else 'cpu')\n",
    "\n",
    "# 模型参数\n",
    "input_dim = 9  # 输入维度\n",
    "num_heads = 2  # 多头注意力头数\n",
    "num_encoder_layers = 2  # 编码器层数\n",
    "dim_feedforward = 512  # 前馈网络维度\n",
    "max_seq_length = 3000  # 序列最大长度\n",
    "num_classes = 1  # 输出类别数\n",
    "\n",
    "model = TransformerModel(input_dim, num_heads, num_encoder_layers, dim_feedforward, max_seq_length, num_classes).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# 假设 train_loader 和 test_loader 已经定义\n",
    "train_losses, validation_losses=train_vali(model, device, train_loader, valid_loader, criterion, optimizer, epochs=100)\n",
    "YXJ.draw_loss(train_losses,validation_losses)\n",
    "test(model, device, valid_loader)\n",
    "test(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d645043b-728b-4e25-9dc6-921cc0bec605",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
